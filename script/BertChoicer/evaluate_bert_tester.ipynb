{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "file_path = \"/home/snt/projects_lujun/temperature_eval_github/temperature_eval/.vscode/api_key.txt\"\n",
    "\n",
    "# # Read the API key from the file\n",
    "with open(file_path, \"r\") as file:\n",
    "    openai.api_key = file.read().strip()\n",
    "\n",
    "\n",
    "def call_openai_api(prompt):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "def evaluate_prediction_with_conversion(task, example, prediction):\n",
    "    # Helper functions for conversion\n",
    "    def bool_to_binary(value):\n",
    "        # Strip whitespace and convert to lowercase for consistency\n",
    "        value = value.strip().lower()\n",
    "\n",
    "        # Check if the string is exactly \"true\"\n",
    "        if value == \"true\":\n",
    "            return 1\n",
    "        elif value == \"false\":\n",
    "            return 0\n",
    "\n",
    "        # Check if the string contains \"true\" but does not contain \"false\"\n",
    "        elif \"true\" in value and \"false\" not in value:\n",
    "            return 1\n",
    "\n",
    "        # Check if the string contains \"false\" but does not contain \"true\"\n",
    "        elif \"false\" in value and \"true\" not in value:\n",
    "            return 0\n",
    "\n",
    "        # If both \"true\" and \"false\" are present or neither is present, return None\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def yes_no_to_binary(value):\n",
    "        # Strip whitespace and convert to lowercase for consistency\n",
    "        value = value.strip().lower()\n",
    "\n",
    "        # Check if the string is exactly \"yes\"\n",
    "        if value == \"yes\":\n",
    "            return 1\n",
    "        elif value == \"no\":\n",
    "            return 0\n",
    "\n",
    "        # Check if the string contains \"yes\" but does not contain \"no\"\n",
    "        elif \"yes\" in value and \"no\" not in value:\n",
    "            return 1\n",
    "\n",
    "        # Check if the string contains \"no\" but does not contain \"yes\"\n",
    "        elif \"no\" in value and \"yes\" not in value:\n",
    "            return 0\n",
    "\n",
    "        # If both \"yes\" and \"no\" are present or neither is present, return None\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def entailment_to_label(value):\n",
    "        # Define the mapping for entailment, contradiction, and neutral\n",
    "        mapping = {\"entailment\": 0, \"contradiction\": 1, \"neutral\": 2}\n",
    "\n",
    "        # Normalize the input by stripping whitespace and converting to lowercase\n",
    "        value = value.strip().lower()\n",
    "\n",
    "        # Check if the input matches exactly one of the keys in the mapping\n",
    "        if value in mapping:\n",
    "            return mapping[value]\n",
    "\n",
    "        # Check if the input contains one of the keys without ambiguity\n",
    "        elif (\n",
    "            \"entailment\" in value\n",
    "            and \"contradiction\" not in value\n",
    "            and \"neutral\" not in value\n",
    "        ):\n",
    "            return mapping[\"entailment\"]\n",
    "        elif (\n",
    "            \"contradiction\" in value\n",
    "            and \"entailment\" not in value\n",
    "            and \"neutral\" not in value\n",
    "        ):\n",
    "            return mapping[\"contradiction\"]\n",
    "        elif (\n",
    "            \"neutral\" in value\n",
    "            and \"entailment\" not in value\n",
    "            and \"contradiction\" not in value\n",
    "        ):\n",
    "            return mapping[\"neutral\"]\n",
    "\n",
    "        # If the input is ambiguous or invalid, return -1\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "    def choice_to_binary(value):\n",
    "        # Normalize the input by stripping whitespace and converting to lowercase\n",
    "        value = value.strip().lower()\n",
    "\n",
    "        # Check if the input contains 'choice 1' and does not contain 'choice 2'\n",
    "        if \"choice 1\" in value and \"choice 2\" not in value:\n",
    "            return 0\n",
    "        elif \"choice 2\" in value:\n",
    "            return 1\n",
    "\n",
    "        # If the input does not match any of the conditions, return None\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # Task-specific evaluation\n",
    "    if task == \"boolq\":\n",
    "        # Convert prediction (True/False) to binary and compare with label (0/1)\n",
    "        return bool_to_binary(prediction) == int(example[\"label\"])\n",
    "\n",
    "    elif task == \"cb\":\n",
    "        # Convert prediction (entailment/contradiction/neutral) to label (0/1/2)\n",
    "        return entailment_to_label(prediction) == int(example[\"label\"])\n",
    "\n",
    "    elif task == \"copa\":\n",
    "        # Convert prediction (choice1/choice2) to binary and compare with label (0/1)\n",
    "        return choice_to_binary(prediction) == int(example[\"label\"])\n",
    "\n",
    "    elif task == \"multirc\":\n",
    "        # Convert prediction (True/False) to binary and compare with label (0/1)\n",
    "        return bool_to_binary(prediction) == int(example[\"label\"])\n",
    "\n",
    "    elif task == \"record\":\n",
    "        # Direct comparison of prediction with the correct entity\n",
    "        processed_answers = [answer.strip().lower() for answer in example[\"answers\"]]\n",
    "        for answer in processed_answers:\n",
    "            if answer in prediction.strip().lower():\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "    elif task == \"rte\":\n",
    "        # Convert prediction (Yes/No) to binary and compare with label (1/0)\n",
    "        return yes_no_to_binary(prediction) == (1 - int(example[\"label\"]))\n",
    "\n",
    "    elif task == \"wic\":\n",
    "        # Convert prediction (Yes/No) to binary and compare with label (0/1)\n",
    "        return yes_no_to_binary(prediction) == int(example[\"label\"])\n",
    "\n",
    "    elif task == \"wsc\":\n",
    "        # Convert prediction (True/False) to binary and compare with label (0/1)\n",
    "        return yes_no_to_binary(prediction) == int(example[\"label\"])\n",
    "\n",
    "    # Default case: unknown task\n",
    "    return False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "df = pd.read_json(\"/home/snt/projects_lujun/temperature_eval_github/temperature_eval/data/Additional_Results/results_superglue_full/vllm_exp_dataset_csv_superGLUE_Meta-Llama-3-8B-Instruct-awq_FUll__20250113_201931.jsonl\", lines=True)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tasks \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m      2\u001b[0m model_names \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m      4\u001b[0m true_default \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "tasks = df['task'].unique()\n",
    "model_names = df['model_name'].unique()\n",
    "\n",
    "true_default = 0\n",
    "true_bert = 0\n",
    "true_gpt = 0\n",
    "total = 0\n",
    "for task in tasks:\n",
    "\n",
    "    df_task = df[df[\"task\"] == task]\n",
    "    for model_name in model_names:\n",
    "\n",
    "        for i, row in tqdm(df_task[df_task[\"model_name\"] == model_name].iterrows(), desc=\"Running Evaluation\", leave=False):\n",
    "            task = row[\"task\"]\n",
    "            example = json.loads(row[\"example\"])\n",
    "            label_default = evaluate_prediction_with_conversion(task, example, row[\"generate_response_default\"])\n",
    "            label_bert = evaluate_prediction_with_conversion(task, example, row[\"generate_response_bert\"])\n",
    "            label_gpt = evaluate_prediction_with_conversion(task, example, row[\"generate_response_gpt\"])\n",
    "\n",
    "            true_default += label_default\n",
    "            true_bert += label_bert\n",
    "            true_gpt += label_gpt\n",
    "            total += 1\n",
    "\n",
    "    true_ratio_default = true_default / total\n",
    "    true_ratio_bert = true_bert / total\n",
    "    true_ratio_gpt = true_gpt / total\n",
    "\n",
    "print(f\"Proportion of True predictions for default model on task {task}: {true_ratio_default:.4f}\")\n",
    "print(f\"Proportion of True predictions for BERT model on task {task}: {true_ratio_bert:.4f}\")\n",
    "print(f\"Proportion of True predictions for GPT model on task {task}: {true_ratio_gpt:.4f}\")\n",
    "# super_glue_df = pd.DataFrame(data_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal_env_transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
