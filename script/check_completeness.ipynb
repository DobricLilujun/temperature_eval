{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal discovery checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filturation before\n",
      "exp_result_Llama-2-7b-chat-hf_20240531222543_952926.csv length: 8807\n",
      "exp_result_Meta-Llama-3-8B-Instruct_20240601004141_953110.csv length: 3500\n",
      "exp_result_Mixtral-8x7B-Instruct-v0.1_20240601004917_953113.csv length: 3500\n",
      "exp_result_Llama-2-7b-chat-hf_20240601003848_953107.csv length: 3500\n",
      "exp_result_Mistral-7B-Instruct-v0.2_20240601004140_953112.csv length: 3500\n",
      "exp_result_Llama-2-13b-chat-hf_20240531225946_952929.csv length: 11505\n",
      "exp_result_Meta-Llama-3-70B-Instruct_20240601005008_953111.csv length: 3500\n",
      "exp_result_Llama-2-70b-chat-hf_20240601004017_953109.csv length: 3500\n",
      "causal_discovery_experiment_prompt.csv length: 3500\n",
      "exp_result_Mixtral-8x22B-Instruct-v0.1_20240601010728_953114.csv length: 680\n",
      "exp_result_Llama-2-13b-chat-hf_20240601004353_953108.csv length: 3500\n",
      "\n",
      "Filturation after\n",
      "exp_result_Meta-Llama-3-8B-Instruct_20240601004141_953110.csv length: 3500\n",
      "exp_result_Mixtral-8x7B-Instruct-v0.1_20240601004917_953113.csv length: 3500\n",
      "exp_result_Llama-2-7b-chat-hf_20240601003848_953107.csv length: 3500\n",
      "exp_result_Mistral-7B-Instruct-v0.2_20240601004140_953112.csv length: 3500\n",
      "exp_result_Meta-Llama-3-70B-Instruct_20240601005008_953111.csv length: 3500\n",
      "exp_result_Llama-2-70b-chat-hf_20240601004017_953109.csv length: 3500\n",
      "exp_result_Llama-2-13b-chat-hf_20240601004353_953108.csv length: 3500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# let's check the completeness of the model output\n",
    "import os\n",
    "\n",
    "folder_path = \"Paper Experiment Results/New/causal_disvoery_improved\"\n",
    "print(\"Filturation before\")\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        length = len(df)\n",
    "        print(f\"{filename} length: {length}\")\n",
    "\n",
    "print()\n",
    "print(\"Filturation after\")\n",
    "folder_path = \"Paper Experiment Results/New_filtered/causal_disvoery_improved\"\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        length = len(df)\n",
    "        print(f\"{filename} length: {length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creativity Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filturation before\n",
      "exp_result_Mixtral-8x22B-Instruct-v0.1_20240531201954_952856.csv length: 84\n",
      "text_generation_api_llama2_13B_4bit_creativity_500.csv length: 90\n",
      "text_generation_api_llama2_70B_4bit_creativity_500.csv length: 90\n",
      "exp_result_Meta-Llama-3-70B-Instruct_20240531194751_952843.csv length: 84\n",
      "exp_result_Meta-Llama-3-8B-Instruct_20240531193412_952839.csv length: 84\n",
      "exp_result_Mistral-7B-Instruct-v0.2_20240531193523_952844.csv length: 84\n",
      "exp_result_Meta-Llama-3-8B-Instruct_20240531192310_952824.csv length: 2\n",
      "text_generation_api_llama2_7B_4bit_creativity_500.csv length: 84\n",
      "exp_result_Mixtral-8x7B-Instruct-v0.1_20240531194727_952845.csv length: 84\n",
      "creativity_experiment_prompt.csv length: 84\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# let's check the completeness of the model output\n",
    "import os\n",
    "\n",
    "folder_path = \"Paper Experiment Results/New/creativity\"\n",
    "print(\"Filturation before\")\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        length = len(df)\n",
    "        print(f\"{filename} length: {length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filturation After\n",
      "exp_result_Meta-Llama-3-8B-Instruct_20240531193412_952839_evaluated.csv length: 1176\n",
      "exp_result_Llama-2-7b-chat-hf.csv length: 84\n",
      "exp_result_Meta-Llama-3-70B-Instruct_20240531194751_952843.csv length: 84\n",
      "exp_result_Meta-Llama-3-70B-Instruct_20240531194751_952843_evaluated.csv length: 466\n",
      "exp_result_Meta-Llama-3-8B-Instruct_20240531193412_952839.csv length: 84\n",
      "exp_result_Mistral-7B-Instruct-v0.2_20240531193523_952844.csv length: 84\n",
      "text_generation_api_llama2_7B_4bit_creativity_500.csv length: 84\n",
      "exp_result_Mixtral-8x7B-Instruct-v0.1_20240531194727_952845.csv length: 84\n",
      "exp_result_Llama-2-13b-chat-hf.csv length: 84\n",
      "exp_result_Llama-2-7b-chat-hf_evaluated.csv length: 1176\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# let's check the completeness of the model output\n",
    "import os\n",
    "\n",
    "folder_path = \"Paper Experiment Results/New_filtered/creativity\"\n",
    "print(\"Filturation After\")\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        length = len(df)\n",
    "        print(f\"{filename} length: {length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Translation Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filturation before\n",
      "exp_result_Llama-2-13b-chat-hf_20240527032307_942274.csv length: 2100\n",
      "exp_result_Mistral-7B-Instruct-v0.2_20240527033832_942278.csv length: 2100\n",
      "ml_experiment_complement_prompt.csv length: 758\n",
      "exp_result_Llama-2-70b-chat-hf_20240520172855_928055.csv length: 2100\n",
      "exp_result_Meta-Llama-3-70B-Instruct_20240531141255_951772.csv length: 2100\n",
      "exp_result_Llama-2-13b-chat-hf_20240527025930_942270.csv length: 32\n",
      "ml_experiment_prompt.csv length: 2100\n",
      "exp_result_Mixtral-8x7B-Instruct-v0.1_20240531200928_952883.csv length: 758\n",
      "exp_result_Mixtral-8x22B-Instruct-v0.1_20240531210513_952917.csv length: 710\n",
      "exp_result_Meta-Llama-3-8B-Instruct_20240520203350_928651.csv length: 2100\n",
      "exp_result_Llama-2-7b-chat-hf_20240520174033_928097.csv length: 2100\n",
      "exp_result_Mixtral-8x7B-Instruct-v0.1_20240527035050_942279.csv length: 1342\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# let's check the completeness of the model output\n",
    "import os\n",
    "\n",
    "folder_path = \"Paper Experiment Results/New/ml\"\n",
    "print(\"Filturation before\")\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        length = len(df)\n",
    "        print(f\"{filename} length: {length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filturation After\n",
      "exp_result_Llama-2-13b-chat-hf_20240527032307_942274.csv length: 2100\n",
      "exp_result_Mistral-7B-Instruct-v0.2_20240527033832_942278.csv length: 2100\n",
      "exp_result_Llama-2-70b-chat-hf_20240520172855_928055.csv length: 2100\n",
      "exp_result_Meta-Llama-3-70B-Instruct_20240531141255_951772.csv length: 2100\n",
      "exp_result_Mixtral-8x7B-Instruct-v0.1.csv length: 2100\n",
      "exp_result_Meta-Llama-3-8B-Instruct_20240520203350_928651.csv length: 2100\n",
      "exp_result_Llama-2-7b-chat-hf_20240520174033_928097.csv length: 2100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# let's check the completeness of the model output\n",
    "import os\n",
    "\n",
    "folder_path = \"Paper Experiment Results/New_filtered/ml\"\n",
    "print(\"Filturation After\")\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        length = len(df)\n",
    "        print(f\"{filename} length: {length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1342, 17)\n",
      "(758, 18)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# let's check the completeness of the model output\n",
    "import os\n",
    "\n",
    "# folder_path = \"Paper Experiment Results/New/ml\"\n",
    "# print(\"Filturation before\")\n",
    "# for filename in os.listdir(folder_path):\n",
    "#     if filename.endswith(\".csv\"):\n",
    "#         file_path = os.path.join(folder_path, filename)\n",
    "#         df = pd.read_csv(file_path)\n",
    "#         length = len(df)\n",
    "#         print(f\"{filename} length: {length}\")\n",
    "test1 = pd.read_csv(\n",
    "    \"/Users/lujun.li/projects/causallm-github/temperature_eval/Paper Experiment Results/New/ml/exp_result_Mixtral-8x7B-Instruct-v0.1_20240527035050_942279.csv\"\n",
    ")\n",
    "print(test1.shape)\n",
    "test2 = pd.read_csv(\n",
    "    \"/Users/lujun.li/projects/causallm-github/temperature_eval/Paper Experiment Results/New/ml/exp_result_Mixtral-8x7B-Instruct-v0.1_20240531200928_952883.csv\"\n",
    ")\n",
    "print(test2.shape)\n",
    "\n",
    "merged_df = pd.concat(\n",
    "    [\n",
    "        test1.loc[:, ~test1.columns.str.startswith(\"Unnamed\")],\n",
    "        test2.loc[:, ~test2.columns.str.startswith(\"Unnamed\")],\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "\n",
    "# merged_df.to_csv(\n",
    "#     \"/Users/lujun.li/projects/causallm-github/temperature_eval/Paper Experiment Results/New_filtered/ml/exp_result_Mixtral-8x7B-Instruct-v0.1.csv\",\n",
    "#     index=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filturation before\n",
      "exp_result_Llama-2-70b-chat-hf_20240531130856_951708.csv length: 1784\n",
      "exp_result_Mixtral-8x22B-Instruct-v0.1_20240508055903.csv length: 2114\n",
      "exp_result_Llama-2-70b-chat-hf_20240601010937_953117.csv length: 330\n",
      "exp_result_Llama-2-7b-chat-hf_20240531130727_951706.csv length: 2114\n",
      "Summary_experiment_prompt.csv length: 2114\n",
      "exp_result_Llama-2-13b-chat-hf_20240531131310_951707.csv length: 2114\n",
      "exp_result_Meta-Llama-3-70B-Instruct_20240508034733.csv length: 2114\n",
      "exp_result_Mistral-7B-Instruct-v0.2_20240531131024_951710.csv length: 2114\n",
      "exp_result_Mixtral-8x7B-Instruct-v0.1_20240508041632.csv length: 2312\n",
      "exp_result_Meta-Llama-3-8B-Instruct_20240531131033_951709.csv length: 2114\n",
      "Summary_experiment_complement_prompt.csv length: 330\n",
      "exp_result_Mixtral-8x7B-Instruct-v0.1_20240507200347.csv length: 2114\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# let's check the completeness of the model output\n",
    "import os\n",
    "\n",
    "folder_path = \"Paper Experiment Results/New/Summary\"\n",
    "print(\"Filturation before\")\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        length = len(df)\n",
    "        print(f\"{filename} length: {length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1784, 15)\n",
      "(330, 16)\n"
     ]
    }
   ],
   "source": [
    "test1 = pd.read_csv(\n",
    "    \"/Users/lujun.li/projects/causallm-github/temperature_eval/Paper Experiment Results/New/Summary/exp_result_Llama-2-70b-chat-hf_20240531130856_951708.csv\"\n",
    ")\n",
    "print(test1.shape)\n",
    "test2 = pd.read_csv(\n",
    "    \"/Users/lujun.li/projects/causallm-github/temperature_eval/Paper Experiment Results/New/Summary/exp_result_Llama-2-70b-chat-hf_20240601010937_953117.csv\"\n",
    ")\n",
    "print(test2.shape)\n",
    "\n",
    "merged_df = pd.concat(\n",
    "    [\n",
    "        test1.loc[:, ~test1.columns.str.startswith(\"Unnamed\")],\n",
    "        test2.loc[:, ~test2.columns.str.startswith(\"Unnamed\")],\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "\n",
    "merged_df.to_csv(\n",
    "    \"/Users/lujun.li/projects/causallm-github/temperature_eval/Paper Experiment Results/New_filtered/Summary/exp_result_Llama-2-70b-chat-hf.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filturation after\n",
      "exp_result_Llama-2-7b-chat-hf_20240531130727_951706.csv length: 2114\n",
      "exp_result_Llama-2-13b-chat-hf_20240531131310_951707.csv length: 2114\n",
      "exp_result_Meta-Llama-3-70B-Instruct_20240508034733.csv length: 2114\n",
      "exp_result_Mistral-7B-Instruct-v0.2_20240531131024_951710.csv length: 2114\n",
      "exp_result_Meta-Llama-3-8B-Instruct_20240531131033_951709.csv length: 2114\n",
      "exp_result_Llama-2-70b-chat-hf.csv length: 2114\n",
      "exp_result_Mixtral-8x7B-Instruct-v0.1_20240507200347.csv length: 2114\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# let's check the completeness of the model output\n",
    "import os\n",
    "\n",
    "folder_path = \"Paper Experiment Results/New_filtered/Summary\"\n",
    "print(\"Filturation after\")\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        length = len(df)\n",
    "        print(f\"{filename} length: {length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-context Learning Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filturation before\n",
      "exp_result_Mistral-7B-Instruct-v0.2_20240531135507_951762.csv length: 1015\n",
      "exp_result_Mixtral-8x22B-Instruct-v0.1_20240531205846_952916.csv length: 937\n",
      "exp_result_Llama-2-70b-chat-hf_20240531032403_951067.csv length: 1\n",
      "exp_result_Llama-2-7b-chat-hf_20240530211958_950783.csv length: 100\n",
      "exp_result_Llama-2-7b-chat-hf_20240519070513.csv length: 100\n",
      "exp_result_Llama-2-7b-chat-hf_20240531015826_950992.csv length: 1015\n",
      "exp_result_Llama-2-7b-chat-hf_20240520114448_927503.csv length: 9\n",
      "exp_result_Llama-2-7b-chat-hf_20240520203710_928653.csv length: 22\n",
      "exp_result_Llama-2-7b-chat-hf_20240520114017.csv length: 6\n",
      "ICL_experiment_prompt.csv length: 1015\n",
      "exp_result_Mixtral-8x7B-Instruct-v0.1_20240531152824_951847.csv length: 1015\n",
      "exp_result_Meta-Llama-3-70B-Instruct_20240531140350_951758.csv length: 1015\n",
      "exp_result_Llama-2-7b-chat-hf_20240530230755_950855.csv length: 100\n",
      "exp_result_Mixtral-8x7B-Instruct-v0.1_20240520222746_928944.csv length: 3018\n",
      "exp_result_Llama-2-70b-chat-hf_20240531134938_951757.csv length: 1015\n",
      "exp_result_Llama-2-13b-chat-hf_20240531032746_951066.csv length: 1015\n",
      "exp_result_Llama-2-7b-chat-hf_20240531012339_950957.csv length: 100\n",
      "exp_result_Meta-Llama-3-8B-Instruct_20240531032532_951068.csv length: 1015\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "folder_path = \"Paper Experiment Results/New/ICL\"\n",
    "print(\"Filturation before\")\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        length = len(df)\n",
    "        print(f\"{filename} length: {length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filturation after\n",
      "exp_result_Mistral-7B-Instruct-v0.2_20240531135507_951762.csv length: 1015\n",
      "exp_result_Llama-2-7b-chat-hf_20240531015826_950992.csv length: 1015\n",
      "exp_result_Mixtral-8x7B-Instruct-v0.1_20240531152824_951847.csv length: 1015\n",
      "exp_result_Meta-Llama-3-70B-Instruct_20240531140350_951758.csv length: 1015\n",
      "exp_result_Llama-2-70b-chat-hf_20240531134938_951757.csv length: 1015\n",
      "exp_result_Llama-2-13b-chat-hf_20240531032746_951066.csv length: 1015\n",
      "exp_result_Meta-Llama-3-8B-Instruct_20240531032532_951068.csv length: 1015\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "folder_path = \"Paper Experiment Results/New_filtered/ICL\"\n",
    "print(\"Filturation after\")\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        length = len(df)\n",
    "        print(f\"{filename} length: {length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instruction Following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filturation before\n",
      "exp_result_Llama-2-70b-chat-hf_20240503110423.csv length: 5\n",
      "exp_result_Llama-2-7b-chat-hf_20240602132301_955580.csv length: 3363\n",
      "IF_experiment_complement_prompt.csv length: 827\n",
      "exp_result_Mistral-7B-Instruct-v0.2_20240503202223.csv length: 3500\n",
      "exp_result_Mistral-7B-Instruct-v0.2_20240502152609.csv length: 4534\n",
      "exp_result_Llama-2-70b-chat-hf_20240502152437.csv length: 484\n",
      "exp_result_Mistral-7B-Instruct-v0.2_20240503200414.csv length: 10\n",
      "exp_result_Llama-2-7b-chat-hf_20240603154533_957156.csv length: 137\n",
      "exp_result_Mixtral-8x22B-Instruct-v0.1_20240502155500.csv length: 77\n",
      "exp_result_Meta-Llama-3-8B-Instruct_20240503202231.csv length: 3500\n",
      "exp_result_Llama-2-7b-chat-hf_20240503105154.csv length: 19\n",
      "exp_result_Mixtral-8x7B-Instruct-v0.1_20240602123231_955509.csv length: 1145\n",
      "exp_result_Llama-2-7b-chat-hf_20240503201935.csv length: 3500\n",
      "exp_result_Llama-2-7b-chat-hf.csv length: 3500\n",
      "exp_result_Llama-2-7b-chat-hf_20240503102846.csv length: 1\n",
      "exp_result_Meta-Llama-3-70B-Instruct_20240601124621_953745.csv length: 827\n",
      "exp_result_Llama-2-7b-chat-hf_20240502152309.csv length: 237\n",
      "exp_result_Llama-2-70b-chat-hf_20240503111010.csv length: 3500\n",
      "exp_result_Llama-2-7b-chat-hf_20240503195416.csv length: 10\n",
      "exp_result_Llama-2-7b-chat-hf_20240602130149_955558.csv length: 44\n",
      "exp_result_Meta-Llama-3-8B-Instruct_20240503200421.csv length: 10\n",
      "IF_experiment_complement_prompt1.csv length: 1176\n",
      "exp_result_Meta-Llama-3-70B-Instruct_20240531141145_951770.csv length: 1323\n",
      "exp_result_Llama-2-13b-chat-hf_20240502152835.csv length: 1807\n",
      "exp_result_Llama-2-70b-chat-hf_20240503174746.csv length: 158\n",
      "exp_result_Llama-2-7b-chat-hf_20240503200121.csv length: 10\n",
      "exp_result_Llama-2-7b-chat-hf_20240503104835.csv length: 1\n",
      "IF_experiment_prompt.csv length: 3500\n",
      "exp_result_Llama-2-13b-chat-hf_20240503200634.csv length: 10\n",
      "exp_result_Mixtral-8x7B-Instruct-v0.1_20240604165637_959734.csv length: 31\n",
      "exp_result_Mixtral-8x7B-Instruct-v0.1_20240531153038_951852.csv length: 1107\n",
      "exp_result_Mixtral-8x7B-Instruct-v0.1_20240601100842_953611.csv length: 1176\n",
      "exp_result.csv length: 13\n",
      "exp_result_Mixtral-8x7B-Instruct-v0.1_20240502153431.csv length: 437\n",
      "exp_result_Llama-2-7b-chat-hf_20240602131602_955571.csv length: 8\n",
      "exp_result_Meta-Llama-3-70B-Instruct_20240601013209_953121.csv length: 1350\n",
      "exp_result_Llama-2-13b-chat-hf_20240503202441.csv length: 3500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "folder_path = \"Paper Experiment Results/New/IF\"\n",
    "print(\"Filturation before\")\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        length = len(df)\n",
    "        print(f\"{filename} length: {length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = pd.read_csv(\n",
    "    \"/home/lujun/local/temperature_eval/Paper Experiment Results/New/IF/exp_result_Mixtral-8x7B-Instruct-v0.1_20240531153038_951852.csv\"\n",
    ")\n",
    "\n",
    "test2 = pd.read_csv(\n",
    "    \"/home/lujun/local/temperature_eval/Paper Experiment Results/New/IF/exp_result_Mixtral-8x7B-Instruct-v0.1_20240601100842_953611.csv\"\n",
    ")\n",
    "\n",
    "test3 = pd.read_csv(\n",
    "    \"/home/lujun/local/temperature_eval/Paper Experiment Results/New/IF/exp_result_Mixtral-8x7B-Instruct-v0.1_20240602123231_955509.csv\"\n",
    ")\n",
    "\n",
    "test4 = pd.read_csv(\n",
    "    \"/home/lujun/local/temperature_eval/Paper Experiment Results/New/IF/exp_result_Mixtral-8x7B-Instruct-v0.1_20240604165637_959734.csv\"\n",
    ")\n",
    "\n",
    "\n",
    "# test3 = pd.read_csv(\n",
    "#     \"/Users/lujun.li/projects/causallm-github/temperature_eval/Paper Experiment Results/New_filtered/IF/exp_result_Meta-Llama-3-70B-Instruct_20240601124621_953745.csv\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat(\n",
    "    [\n",
    "        test1.loc[:, ~test1.columns.str.startswith(\"Unnamed\")],\n",
    "        test2.loc[:, ~test2.columns.str.startswith(\"Unnamed\")],\n",
    "        test3.loc[:, ~test3.columns.str.startswith(\"Unnamed\")],\n",
    "        test4.loc[:, ~test4.columns.str.startswith(\"Unnamed\")],\n",
    "    ],\n",
    "    axis=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\n",
    "    \"/home/lujun/local/temperature_eval/Paper Experiment Results/New_filtered/IF/exp_result_Mixtral-8x7B-Instruct-v0.1.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filturation before\n",
      "exp_result_Mistral-7B-Instruct-v0.2_20240503202223.csv length: 3500\n",
      "exp_result_Meta-Llama-3-8B-Instruct_20240503202231.csv length: 3500\n",
      "exp_result_Llama-2-13b-chat-hf_20240503202441_evaluated copy 2.csv length: 2486\n",
      "exp_result_Mixtral-8x7B-Instruct-v0.1.csv length: 3459\n",
      "exp_result_Llama-2-7b-chat-hf.csv length: 3500\n",
      "exp_result_Meta-Llama-3-70B-Instruct_evaluated.csv length: 313\n",
      "exp_result_Llama-2-70b-chat-hf_20240503111010_evaluated.csv length: 3499\n",
      "exp_result_Llama-2-70b-chat-hf_20240503111010.csv length: 3500\n",
      "exp_result_Meta-Llama-3-70B-Instruct.csv length: 3500\n",
      "exp_result_Llama-2-13b-chat-hf_20240503202441_evaluated.csv length: 3510\n",
      "exp_result_Meta-Llama-3-8B-Instruct_20240503202231_evaluated.csv length: 3500\n",
      "exp_result_Mistral-7B-Instruct-v0.2_20240503202223_evaluated.csv length: 244\n",
      "exp_result_Llama-2-13b-chat-hf_20240503202441.csv length: 3500\n",
      "exp_result_Llama-2-7b-chat-hf_evaluated.csv length: 2046\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "folder_path = \"Paper Experiment Results/New_filtered/IF\"\n",
    "print(\"Filturation before\")\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        length = len(df)\n",
    "        print(f\"{filename} length: {length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causalAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
