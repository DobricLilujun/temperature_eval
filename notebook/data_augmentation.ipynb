{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "\n",
    "openai.api_key = \"sk-pA\"\n",
    "\n",
    "ability_dict = {\n",
    "    \"CR\": \"Causal Reasoning\",\n",
    "    \"CT\": \"Creativity\",\n",
    "    \"ICL\": \"In-context Learning\",\n",
    "    \"IF\": \"Instruction Following\",\n",
    "    \"MT\": \"Machine Translation\",\n",
    "    \"SUMM\": \"Summarization\",\n",
    "}\n",
    "\n",
    "inspiration_prompt_template = \"\"\"\n",
    "I want you to take on the role of an ingenious and imaginative assistant. Your mission is to spark creativity and inspire innovative thinking. For the given topic of {capability} ability, please provide a truly unique and thought-provoking inspiration sentence. \n",
    "\n",
    "This inspiration should:\n",
    "1. Challenge conventional thinking and encourage thinking outside the box.\n",
    "2. Stimulate a wide array of creative and critical ideas.\n",
    "3. Serve as a catalyst for generating engaging and meaningful tasks or questions.\n",
    "\n",
    "Be bold, imaginative, and daring in your approach. Let's create something extraordinary!\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "The goal of this task is to evaluate the model's ability to demonstrate {capability}. Imagine you are designing a challenging yet creative evaluation question. Using the example provided below as a guide and the inspiration as a springboard, craft a new and exciting question that captures the essence of this capability. \n",
    "\n",
    "Make the question engaging, thought-provoking, and appropriately complex, while ensuring it evaluates the desired skill effectively. Generate a JSON object with the following fields: question (string), reference (string).\n",
    "\n",
    "\n",
    "Here are the inputs:\n",
    "- Example: {example}\n",
    "- Inspiration: {inspiration}\n",
    "\n",
    "Let your imagination flow and create a question that stands out!\n",
    "\"\"\"\n",
    "\n",
    "output_dir = \"/home/lujun_li/projects/temperature_eval/data/Augemented/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for ability_code, capability_name in ability_dict.items():\n",
    "    try:\n",
    "        target_df = pd.read_csv(\n",
    "            f\"/home/lujun_li/projects/temperature_eval/data/Intermediate/{ability_code}.csv\"\n",
    "        )\n",
    "\n",
    "    except (FileNotFoundError, KeyError):\n",
    "        print(\n",
    "            f\"Warning: File for {ability_code} not found or invalid format, skipping.\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    generated_data = []\n",
    "\n",
    "    if ability_code == \"MT\":\n",
    "        repetition = 100\n",
    "    if ability_code == \"CT\":\n",
    "        repetition = 10\n",
    "    else:\n",
    "        repetition = 50\n",
    "    for _ in repetition(repetition):\n",
    "        random_row = target_df.sample(n=1, random_state=random.randint(0, 100)).iloc[0]\n",
    "        example = random_row[\"input\"]  \n",
    "\n",
    "        inspiration_prompt = inspiration_prompt_template.format(\n",
    "            capability=capability_name\n",
    "        )\n",
    "        inspiration_response = openai.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": inspiration_prompt},\n",
    "            ],\n",
    "            temperature=0.7,  \n",
    "        )\n",
    "        inspiration = inspiration_response.choices[0].message.content.strip()\n",
    "\n",
    "        prompt = prompt_template.format(\n",
    "            capability=capability_name,\n",
    "            example=example,\n",
    "            inspiration=inspiration,\n",
    "        )\n",
    "        question_response = openai.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are an assistant that only outputs JSON-formatted data. No extra explanations, no text outside JSON, and strict adherence to the required format.\",\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            temperature=0.7, \n",
    "        )\n",
    "        question_json = question_response.choices[0].message.content.strip()\n",
    "\n",
    "        try:\n",
    "            question_json = json.loads(question_json)\n",
    "            question = question_json.get(\"question\", \"\")\n",
    "            reference = question_json.get(\"reference\", \"\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Invalid JSON format: {question_json}\")\n",
    "            question = \"\"\n",
    "            reference = \"\"\n",
    "        generated_data.append(\n",
    "            {\n",
    "                \"Ability\": capability_name,\n",
    "                \"Example\": example,\n",
    "                \"Inspiration\": inspiration,\n",
    "                \"Question\": question,\n",
    "                \"Reference\": reference,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        print(f\"Ability: {capability_name}\")\n",
    "        print(f\"Inspiration: {inspiration}\")\n",
    "        print(f\"Generated Question: {question_json}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    output_file = os.path.join(output_dir, f\"{ability_code}_generated_questions.csv\")\n",
    "    pd.DataFrame(generated_data).to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "    print(f\"Saved 50 questions for {capability_name} to {output_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "CR_df = pd.read_csv(\n",
    "    \"/home/snt/projects_lujun/temperature_eval_github/temperature_eval/data/Augemented/CR_generated_questions.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CT_df = pd.read_csv(\n",
    "    \"/home/snt/projects_lujun/temperature_eval_github/temperature_eval/data/Augemented/CT_generated_questions.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICL_df = pd.read_csv(\n",
    "    \"/home/snt/projects_lujun/temperature_eval_github/temperature_eval/data/Augemented/ICL_generated_questions.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  98%|█████████▊| 49/50 [03:03<00:03,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid JSON format for question: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows: 100%|██████████| 50/50 [03:06<00:00,  3.73s/it]\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "file_path = \"/home/snt/projects_lujun/temperature_eval_github/temperature_eval/.vscode/api_key.txt\"\n",
    "with open(file_path, \"r\") as file:\n",
    "    api_key = file.read().strip()\n",
    "openai.api_key = api_key\n",
    "\n",
    "IF_df = pd.read_csv(\n",
    "    \"/home/snt/projects_lujun/temperature_eval_github/temperature_eval/data/Augemented/IF_generated_questions.csv\"\n",
    ")\n",
    "\n",
    "prompt_template = \"\"\"I would like you to generate three key instruction verification questions based on the following input question, which I asked the model:\n",
    "\n",
    "{question}\n",
    "\n",
    "These questions should assess the model's ability to accurately follow the instructions provided in the initial question. Please return the three important questions as a JSON object with the following fields:\n",
    "\n",
    "\"Q1\" (string): The first key question to verify the model's ability to follow the instruction.\n",
    "\"Q2\" (string): The second key question to verify the model's ability to follow the instruction.\n",
    "\"Q3\" (string): The third key question to verify the model's ability to follow the instruction.\n",
    "Ensure that the questions are directly relevant to the instruction and are crucial for evaluating the model’s performance in following the given task.\n",
    "\"\"\"\n",
    "\n",
    "with open(\n",
    "    \"/home/snt/projects_lujun/temperature_eval_github/temperature_eval/data/Augemented/output.jsonl\",\n",
    "    \"a\",\n",
    ") as jsonl_file:\n",
    "    # Wrap the iteration with tqdm to display a progress bar\n",
    "    for i, row in tqdm(IF_df.iterrows(), total=IF_df.shape[0], desc=\"Processing Rows\"):\n",
    "        update_row = row.copy()\n",
    "        question = row[\"Question\"]\n",
    "        prompt = prompt_template.format(question=question)\n",
    "\n",
    "        try:\n",
    "            inspiration_response = (\n",
    "                openai.chat.completions.create(\n",
    "                    model=\"gpt-4\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                        {\"role\": \"user\", \"content\": prompt},\n",
    "                    ],\n",
    "                    temperature=0.7,  # Adjust randomness\n",
    "                )\n",
    "                .choices[0]\n",
    "                .message.content.strip()\n",
    "            )\n",
    "\n",
    "            # Attempt to parse the JSON response\n",
    "            question_json = json.loads(inspiration_response)\n",
    "            Q1 = question_json.get(\"Q1\", \"\")\n",
    "            Q2 = question_json.get(\"Q2\", \"\")\n",
    "            Q3 = question_json.get(\"Q3\", \"\")\n",
    "            Qs = [Q1, Q2, Q3]\n",
    "\n",
    "            update_row[\"questions_to_be_followed\"] = str(Qs)\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Invalid JSON format for question: {question}\")\n",
    "            Qs = [\"\", \"\", \"\"]\n",
    "            update_row[\"questions_to_be_followed\"] = str(\n",
    "                Qs\n",
    "            )  # Store empty list if error occurs\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing question: {question}. Error: {e}\")\n",
    "            Qs = [\"\", \"\", \"\"]\n",
    "            update_row[\"questions_to_be_followed\"] = str(\n",
    "                Qs\n",
    "            )  # Store empty list in case of other errors\n",
    "\n",
    "        # Write the updated row as a JSON object to the jsonl file\n",
    "        jsonl_file.write(json.dumps(update_row.to_dict()) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causalLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
