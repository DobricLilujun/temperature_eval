{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert Model Fine-tuning\n",
    "\n",
    "This notebook primarily utilizes the state-of-the-art (SOTA) Google BERT model, originally designed to learn how to order shuffled sentences within a paragraph. While most use cases focus on classification and Named Entity Recognition (NER), we often need to fine-tune this model to suit our specific needs.\n",
    "\n",
    "One important consideration is that the context input length is limited to less than 512 tokens due to the model’s structural constraints. Additionally, high-quality training data is essential to achieve good generalization. We also test other spliting of dataset and we obtain the similar accuracy (Originally set to 42) but different trace of training loss. This highlights that the model learns something from the data.\n",
    "\n",
    "Model used: BERT-base-multilingual-uncased\n",
    "\n",
    "This [slides](https://docs.google.com/presentation/d/165GxBIZ-Jxk8uaEKK9h02GtFsKsCCQdm8ouar2JkCKU/edit?usp=sharing) has more details see here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/snt/miniconda3/envs/causal_env_transformer/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import gc\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import (\n",
    "    TensorDataset,\n",
    "    DataLoader,\n",
    "    RandomSampler,\n",
    "    SequentialSampler,\n",
    "    random_split,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import (\n",
    "    BertForSequenceClassification,\n",
    "    AdamW,\n",
    "    BertConfig,\n",
    "    BertTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "import os\n",
    "\n",
    "# Specify your cuda device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data For Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/home/snt/projects_lujun/temperature_eval_github/temperature_eval/data/Bert/all_data_for_bert_training_augmented_opensource.csv\"\n",
    "\n",
    "# Load the dataset from a CSV file\n",
    "dataset = pd.read_csv(dataset_path)\n",
    "dataset[\"ability\"] = dataset[\"ability\"].replace({\"SUM\": \"SUMM\"})\n",
    "\n",
    "# Convert the 'Rappel' column to a categorical type\n",
    "dataset[\"ability\"] = dataset[\"ability\"].astype(\"category\")\n",
    "\n",
    "# Encode the categorical 'Rappel' column as numerical codes\n",
    "dataset[\"ability\"] = dataset[\"ability\"].cat.codes\n",
    "\n",
    "# Extract the email content and labels into separate variables\n",
    "texts = dataset.initial_prompt.values\n",
    "labels = dataset.ability.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing texts: 100%|██████████| 30214/30214 [02:29<00:00, 202.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Define the path to the pre-trained model\n",
    "model = \"/home/snt/llm_models/bert-base-multilingual-uncased\"\n",
    "\n",
    "# Initialize the tokenizer from the pre-trained model, with lowercasing enabled\n",
    "tokenizer = BertTokenizer.from_pretrained(model, do_lower_case=True)\n",
    "\n",
    "# Get the maximum token length supported by the tokenizer\n",
    "max_token_length = tokenizer.model_max_length\n",
    "\n",
    "# Initialize a variable to keep track of the maximum length of tokenized input\n",
    "max_len = 0\n",
    "\n",
    "# Iterate over each text in the dataset\n",
    "for text in tqdm(texts, desc=\"Processing texts\"):\n",
    "    # Tokenize the text and add special tokens\n",
    "    input_ids = tokenizer.encode(text, add_special_tokens=True, truncation=True)\n",
    "    # Update max_len with the length of the current tokenized input if it's greater than the current max_len\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "\n",
    "# Determine the maximum padding length\n",
    "if max_len < max_token_length:\n",
    "    max_padding = max_len\n",
    "else:\n",
    "    max_padding = max_token_length\n",
    "\n",
    "max_padding  # Need to padding to 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding texts:   0%|          | 0/30214 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/snt/miniconda3/envs/causal_env_transformer/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Encoding texts: 100%|██████████| 30214/30214 [02:37<00:00, 191.66it/s]\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for text in tqdm(texts, desc=\"Encoding texts\"):\n",
    "    # `encode_plus` (1) Tokenize the sentence. (2) Prepend the `[CLS]` token to the start. (3) Append the `[SEP]` token to the end.\n",
    "    #  (4) Map tokens to their IDs. (5) Pad or truncate the sentence to `max_length` (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        text,  # Sentence to encode.\n",
    "        add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "        max_length=max_padding,  # Pad & truncate all sentences.\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,  # Construct attn. masks.\n",
    "        return_tensors=\"pt\",  # Return pytorch tensors.\n",
    "    )\n",
    "\n",
    "    input_ids.append(encoded_dict[\"input_ids\"])\n",
    "    attention_masks.append(encoded_dict[\"attention_mask\"])\n",
    "\n",
    "# Convert the lists into tensors. [Samples, max_length]\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels).to(torch.int64)\n",
    "labels = torch.nn.functional.one_hot(\n",
    "    labels\n",
    ").float()  # Change to Float in order to calcualte Loss [Samples, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18,128 training samples\n",
      "12,086 validation samples\n"
     ]
    }
   ],
   "source": [
    "# Combine the training inputs into a TensorDataset\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# Set the random seed for reproducibility and shuffle the dataset\n",
    "torch.manual_seed(40)  # Orginally set to 42 for training\n",
    "sample_indices = torch.randperm(len(dataset))\n",
    "test_dataset = torch.utils.data.Subset(dataset, sample_indices)\n",
    "\n",
    "# Calculate the sizes for training and validation datasets\n",
    "train_size = int(0.6 * len(test_dataset))\n",
    "val_size = len(test_dataset) - train_size\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_dataset, val_dataset = random_split(test_dataset, [train_size, val_size])\n",
    "\n",
    "# Print the number of samples in the training and validation sets\n",
    "print(\"{:>5,} training samples\".format(train_size))\n",
    "print(\"{:>5,} validation samples\".format(val_size))\n",
    "\n",
    "# Dataset preparation\n",
    "batch_size = 96\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,  # The training samples.\n",
    "    sampler=RandomSampler(train_dataset),  # Select batches randomly\n",
    "    batch_size=batch_size,  # Trains with this batch size.\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "    val_dataset,  # The validation samples.\n",
    "    sampler=SequentialSampler(val_dataset),  # Pull out batches sequentially.\n",
    "    batch_size=batch_size,  # Evaluate with this batch size.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Engine Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"/home/snt/llm_models/bert-base-multilingual-uncased\"\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    model,  # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels=6,  # The number of output labels--2 for binary classification.\n",
    "    output_attentions=False,  # Whether the model returns attentions weights.\n",
    "    output_hidden_states=False,  # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=1e-6,  # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "    eps=1e-8,  # args.adam_epsilon  - default is 1e-8.\n",
    ")\n",
    "\n",
    "# Number of training epochs.\n",
    "epochs = 10\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs].\n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler. (This is important to decrease learning while training)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,  # Default value in run_glue.py\n",
    "    num_training_steps=total_steps,\n",
    ")\n",
    "\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = np.argmax(labels, axis=1).flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "b_labels_np = labels.cpu().numpy()\n",
    "\n",
    "labels_np = np.argmax(b_labels_np, axis=1)  \n",
    "\n",
    "unique_labels = np.unique(labels_np) \n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=unique_labels, y=labels_np\n",
    ")\n",
    "\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# dataset = train_dataloader.dataset  # Getting the underlying dataset of the DataLoader\n",
    "\n",
    "# # Shuffle the dataset and select 100 random indices\n",
    "# random_indices = random.sample(range(len(dataset)), 100)\n",
    "\n",
    "# # Create a Subset of the dataset with the selected indices\n",
    "# test_subset = Subset(dataset, random_indices)\n",
    "\n",
    "# # Create a DataLoader for the 100 samples\n",
    "# test_dataloader = DataLoader(test_subset, batch_size=32, shuffle=False)  # Adjust batch_size if necessary\n",
    "\n",
    "# dataset = validation_dataloader.dataset  # Getting the underlying dataset of the DataLoader\n",
    "\n",
    "# # Shuffle the dataset and select 100 random indices\n",
    "# random_indices = random.sample(range(len(dataset)), 100)\n",
    "\n",
    "# # Create a Subset of the dataset with the selected indices\n",
    "# test_subset = Subset(dataset, random_indices)\n",
    "\n",
    "# Create a DataLoader for the 100 samples\n",
    "# val_test_dataloader = DataLoader(test_subset, batch_size=32, shuffle=False)  # Adjust batch_size if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10:   0%|          | 0/189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10: 100%|██████████| 189/189 [05:42<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.56\n",
      "  Training epcoh took: 0:05:43\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.73\n",
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/10: 100%|██████████| 189/189 [05:47<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.37\n",
      "  Training epcoh took: 0:05:47\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.79\n",
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/10: 100%|██████████| 189/189 [05:47<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.29\n",
      "  Training epcoh took: 0:05:47\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.89\n",
      "\n",
      "======== Epoch 4 / 10 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/10: 100%|██████████| 189/189 [05:47<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.24\n",
      "  Training epcoh took: 0:05:47\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.92\n",
      "\n",
      "======== Epoch 5 / 10 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/10: 100%|██████████| 189/189 [05:47<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.22\n",
      "  Training epcoh took: 0:05:47\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.94\n",
      "\n",
      "======== Epoch 6 / 10 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/10: 100%|██████████| 189/189 [05:47<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.20\n",
      "  Training epcoh took: 0:05:47\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.94\n",
      "\n",
      "======== Epoch 7 / 10 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/10: 100%|██████████| 189/189 [05:47<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.18\n",
      "  Training epcoh took: 0:05:47\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.94\n",
      "\n",
      "======== Epoch 8 / 10 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/10: 100%|██████████| 189/189 [05:47<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.17\n",
      "  Training epcoh took: 0:05:47\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.95\n",
      "\n",
      "======== Epoch 9 / 10 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/10: 100%|██████████| 189/189 [05:47<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.17\n",
      "  Training epcoh took: 0:05:48\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.95\n",
      "\n",
      "======== Epoch 10 / 10 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/10: 100%|██████████| 189/189 [05:47<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.17\n",
      "  Training epcoh took: 0:05:47\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.95\n",
      "\n",
      "Training complete!\n",
      "Total training took 1:11:35 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "seed_val = 43  # Set the seed value for reproducibility originally 42\n",
    "random.seed(seed_val)  # Set the seed for the Python random module\n",
    "np.random.seed(seed_val)  # Set the seed for NumPy's random number generator\n",
    "torch.manual_seed(seed_val)  # Set the seed for PyTorch's random number generator\n",
    "torch.cuda.manual_seed_all(\n",
    "    seed_val\n",
    ")  # Set the seed for all CUDA (GPU) operations in PyTorch\n",
    "\n",
    "\n",
    "training_stats = []  # Initialize an empty list to store training statistics\n",
    "total_t0 = time.time()  # Measure the total training time for the whole run.\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    # Perform one full pass over the training set.\n",
    "    print(\"\")\n",
    "    print(\"======== Epoch {:} / {:} ========\".format(epoch_i + 1, epochs))\n",
    "    print(\"Training...\")\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "    for step, batch in enumerate(\n",
    "        tqdm(train_dataloader, desc=\"Training Epoch {}/{}\".format(epoch_i + 1, epochs))\n",
    "    ):\n",
    "        # Unpack this training batch from our dataloader.\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids\n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(\n",
    "            b_input_ids,\n",
    "            token_type_ids=None,\n",
    "            attention_mask=b_input_mask,\n",
    "            labels=b_labels,\n",
    "        )\n",
    "        loss = output.loss  # Loss is calculate by forwarding\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    t0 = time.time()\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "    # Tracking variables\n",
    "    total_eval_accuracy = 0\n",
    "    best_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():\n",
    "            output = model(\n",
    "                b_input_ids,\n",
    "                token_type_ids=None,\n",
    "                attention_mask=b_input_mask,\n",
    "                labels=b_labels,\n",
    "            )\n",
    "        loss = output.loss\n",
    "        labels_int = torch.argmax(b_labels, dim=1)\n",
    "        loss = loss * class_weights_tensor[labels_int].mean()\n",
    "\n",
    "        total_eval_loss += loss.item()\n",
    "        # Move logits and labels to CPU if we are using GPU\n",
    "        logits = output.logits\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to(\"cpu\").numpy()\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    if avg_val_accuracy > best_eval_accuracy:\n",
    "        torch.save(\n",
    "            model,\n",
    "            f\"/home/snt/projects_lujun/temperature_eval_github/temperature_eval/data/Bert/training/bert_model_target_\",\n",
    "        )\n",
    "        best_eval_accuracy = avg_val_accuracy\n",
    "    torch.save(\n",
    "        model,\n",
    "        f\"/home/snt/projects_lujun/temperature_eval_github/temperature_eval/data/Bert/training/bert_model_target_{epoch_i}\",\n",
    "    )\n",
    "    # print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    # print(\"  Validation took: {:}\".format(validation_time))\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            \"epoch\": epoch_i + 1,\n",
    "            \"Training Loss\": avg_train_loss,\n",
    "            \"Valid. Loss\": avg_val_loss,\n",
    "            \"Valid. Accur.\": avg_val_accuracy,\n",
    "            \"Training Time\": training_time,\n",
    "            \"Validation Time\": validation_time,\n",
    "        }\n",
    "    )\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time() - total_t0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal_env_transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
