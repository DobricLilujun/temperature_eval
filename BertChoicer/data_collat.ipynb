{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collector For Other Work For Bert Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"/home/snt/projects_lujun/temperature_eval_github/temperature_eval/data/Bert/all_data_for_bert_training.csv\"\n",
    ")\n",
    "\n",
    "df = df[[\"initial_prompt\", \"ability\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Instruction Number', 'Instruction ', 'Number of Constraints',\n",
      "       'Constraints'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "ct_df1 = pd.read_csv(\n",
    "    \"/home/snt/projects_lujun/temperature_eval_github/temperature_eval/data/reference_code/cs4_benchmark/CS4_dataset/Instruction-based Constraints.csv\"\n",
    ")\n",
    "print(ct_df1.columns)\n",
    "ct_df1[\"initial_prompt\"] = ct_df1[\"Instruction \"] + \"\\n\" + ct_df1[\"Constraints\"]\n",
    "\n",
    "ct_df1[\"ability\"] = \"CT\"\n",
    "ct_df1 = ct_df1[[\"initial_prompt\", \"ability\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_df2 = pd.read_csv(\n",
    "    \"/home/snt/projects_lujun/temperature_eval_github/temperature_eval/data/reference_code/cs4_benchmark/CS4_dataset/Story-based Constraints.csv\"\n",
    ")\n",
    "\n",
    "ct_df2[\"initial_prompt\"] = ct_df2[\"Instruction \"] + \"\\n\" + ct_df2[\"Constraints\"]\n",
    "\n",
    "ct_df2[\"ability\"] = \"CT\"\n",
    "ct_df2 = ct_df2[[\"initial_prompt\", \"ability\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"keyword\"],\n",
    "    template=(\n",
    "        \"I'll be submitting your next responses to a 'Good Scientific Idea' expert review panel. If \"\n",
    "        \"they consider your idea to be a good one, you'll receive a reward. Your assigned keyword \"\n",
    "        \"is: '{keyword}'. You may provide background information. The idea MUST be within 100 words \"\n",
    "        \"(including background information). (Note: good scientific ideas should be novel, verifiable, \"\n",
    "        \"practically valuable, and able to advance the field.).\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "ct_df3 = pd.read_csv(\n",
    "    \"/home/snt/projects_lujun/temperature_eval_github/temperature_eval/data/reference_code/liveideabench/liveideabench_hf.csv\"\n",
    ")[0:1000]\n",
    "\n",
    "ct_df3[\"initial_prompt\"] = ct_df3[\"keywords\"].apply(\n",
    "    lambda x: prompt_template.format(keyword=x)\n",
    ")\n",
    "\n",
    "ct_df3[\"ability\"] = \"CT\"\n",
    "ct_df3 = ct_df3[[\"initial_prompt\", \"ability\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.concat([df, ct_df1, ct_df2, ct_df3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ability\n",
       "CR     24732\n",
       "IF     24426\n",
       "SUM    14798\n",
       "MT     14699\n",
       "ICL     3920\n",
       "CT      2088\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.ability.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct_df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICL_df = pd.read_csv(\n",
    "    \"/home/snt/projects_lujun/temperature_eval_github/temperature_eval/data/Results/ICL/exp_result_Meta-Llama-3-8B-Instruct_20240531032532_951068_evaluated.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICL_df = (\n",
    "    ICL_df[ICL_df[\"dataset\"] == \"triviaqa_e\"]\n",
    "    .drop_duplicates(subset=[\"initial_prompt\"])\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICL_df[\"ability\"] = \"ICL\"\n",
    "ICL_df = ICL_df[[\"initial_prompt\", \"ability\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat([main_df, ICL_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ability\n",
       "CR     24732\n",
       "IF     24426\n",
       "SUM    14798\n",
       "MT     14699\n",
       "ICL     3985\n",
       "CT      2088\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.ability.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.drop_duplicates(subset=[\"initial_prompt\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ability\n",
       "MT     600\n",
       "CT     556\n",
       "IF     501\n",
       "ICL    145\n",
       "SUM    109\n",
       "CR      50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.ability.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['initial_prompt', 'ability'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRASS_FTM_main_data_set_df = pd.read_csv(\n",
    "    \"/home/snt/projects_lujun/temperature_eval_github/temperature_eval/data/Source/CR/CRASS-data-set/CRASS_FTM_main_data_set.csv\",\n",
    "    encoding=\"latin1\",\n",
    "    sep=\";\",\n",
    ")\n",
    "\n",
    "CRASS_FTM_main_data_set_df[\"ability\"] = \"CR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "arraycounter = 0\n",
    "system_message = \"You are a conscientious assistant, and you must answer my questions exactly as my questions require.\"\n",
    "instruction = \"Please reference the following three examples (including premise, query, possible answers, and correct answer) to answer the final query.\"\n",
    "initial_prompt = \"\"\"\n",
    "Instruction: {system_message}\n",
    "Input: \n",
    "{INSTRUCTION}\n",
    "{INPUT}\n",
    "\"\"\"\n",
    "mixtral_instruct_initial_prompt = \"\"\"<s>[INST]\n",
    "{system_message}\n",
    "{INSTRUCTION}\n",
    "{INPUT}\n",
    "[/INST] \n",
    "</s>\"\"\"\n",
    "\n",
    "llama2_chat_initial_prompt = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "{system_message}\n",
    "<</SYS>>\n",
    "{INSTRUCTION}\n",
    "{INPUT}\n",
    "[/INST]\n",
    "\"\"\"\n",
    "\n",
    "llama3_chat_init_prompt = \"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "{system_message}\n",
    "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "{INSTRUCTION}\n",
    "{INPUT}\n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "few_shot_prompt = \"\"\"Premise: A feather falls from a skyscraper. \n",
    "Query: What would have happened if a computer had fallen from the skyscraper? \n",
    "Possible answers: The computer would have remained intact. That is not possible. The computer would have been crushed. \n",
    "Correct answer: The computer would have been crushed.\n",
    "\n",
    "Premise: A lightning hits a tree. \n",
    "Query: What would have happened if a marble would have hit the tree? \n",
    "Possible answers: It would have burned down. Nothing special would have happened. The tree would have kissed the lightning. \n",
    "Correct answer: Nothing special would have happened. \n",
    "\n",
    "Premise: A man drinks a beer. \n",
    "Query: What would have happened if the man had drunk a rainbow? \n",
    "Possible answers: It would have been tasty. It would have been awful. That is not possible. \n",
    "Correct answer: That is not possible.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for _, row in CRASS_FTM_main_data_set_df.iterrows():\n",
    "    instruction = \"Please reference the following three examples (including premise, query, possible answers, and correct answer) to answer the final query.\"\n",
    "    few_shot_prompt = \"\"\"\n",
    "    Examples: \n",
    "\n",
    "    Premise: {}\n",
    "    Query: {}\n",
    "    Possible answers: {}\n",
    "    Correct answer: {}\n",
    "    \"\"\".format(\n",
    "        row.Premise, row.QCC, row.CorrectAnswer, row.Answer1\n",
    "    )\n",
    "\n",
    "    hf_inputs = \"Premise: {}\\nQuery: {}\".format(row.Premise, row.QCC)\n",
    "    hf_cl1 = row.CorrectAnswer\n",
    "    hf_cl2 = row.Answer1\n",
    "    hf_cl3 = row.Answer2\n",
    "    prompt = (\n",
    "        few_shot_prompt\n",
    "        + hf_inputs\n",
    "        + \"\\nPossible answers: \"\n",
    "        + hf_cl1\n",
    "        + hf_cl2\n",
    "        + hf_cl3\n",
    "        + \"\\nCorrect answer:\"\n",
    "    )\n",
    "    # Add instruction and prompt to dataframe\n",
    "    CRASS_FTM_main_data_set_df.at[_, \"instruction\"] = instruction\n",
    "    CRASS_FTM_main_data_set_df.at[_, \"input\"] = prompt\n",
    "\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "initial_prompt_template = PromptTemplate.from_template(initial_prompt)\n",
    "llama2_chat_initial_prompt_template = PromptTemplate.from_template(\n",
    "    llama2_chat_initial_prompt\n",
    ")\n",
    "mixtral_instruct_initial_prompt_template = PromptTemplate.from_template(\n",
    "    mixtral_instruct_initial_prompt\n",
    ")\n",
    "llama3_chat_initial_prompt_template = PromptTemplate.from_template(\n",
    "    llama3_chat_init_prompt\n",
    ")\n",
    "\n",
    "\n",
    "def generate_initial_prompts(row):\n",
    "    input = row[\"input\"]\n",
    "    instruction = row[\"instruction\"]\n",
    "    initial_prompt = initial_prompt_template.format(\n",
    "        INSTRUCTION=instruction, INPUT=input, system_message=system_message\n",
    "    )\n",
    "\n",
    "    llama2_chat_initial_prompt = llama2_chat_initial_prompt_template.format(\n",
    "        INSTRUCTION=instruction, INPUT=input, system_message=system_message\n",
    "    )\n",
    "\n",
    "    llama3_chat_initial_prompt = llama3_chat_initial_prompt_template.format(\n",
    "        INSTRUCTION=instruction, INPUT=input, system_message=system_message\n",
    "    )\n",
    "\n",
    "    mixtral_instruct_initial_prompt = mixtral_instruct_initial_prompt_template.format(\n",
    "        INSTRUCTION=instruction, INPUT=input, system_message=system_message\n",
    "    )\n",
    "\n",
    "    row[\"initial_prompt\"] = initial_prompt\n",
    "    row[\"llama2_chat_initial_prompt\"] = llama2_chat_initial_prompt\n",
    "    row[\"mixtral_instruct_initial_prompt\"] = mixtral_instruct_initial_prompt\n",
    "    row[\"llama3_chat_initial_prompt\"] = llama3_chat_initial_prompt\n",
    "    row[\"INSTRUCTION\"] = input\n",
    "    row[\"INPUT\"] = instruction\n",
    "    return row\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "CRASS_FTM_main_data_set_df = CRASS_FTM_main_data_set_df.apply(\n",
    "    generate_initial_prompts, axis=1\n",
    ")\n",
    "temperatures = np.arange(0.1, 2.0, 0.3)\n",
    "temperature_df = pd.DataFrame({\"Temperature\": temperatures})\n",
    "merged_df = temperature_df.merge(CRASS_FTM_main_data_set_df, how=\"cross\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CR_df = CRASS_FTM_main_data_set_df[[\"initial_prompt\", \"ability\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat([CR_df, new_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ability\n",
       "MT     600\n",
       "CT     556\n",
       "IF     501\n",
       "CR     324\n",
       "ICL    145\n",
       "SUM    109\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.ability.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\n",
    "    \"/home/snt/projects_lujun/temperature_eval_github/temperature_eval/data/Bert/all_data_for_bert_training_non_repetitive.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "\n",
    "def synonym_replacement(sentence, n=1):\n",
    "    words = sentence.split()\n",
    "    new_words = words.copy()\n",
    "    random_word_list = list(set([word for word in words if wordnet.synsets(word)]))\n",
    "    random.shuffle(random_word_list)\n",
    "\n",
    "    for random_word in random_word_list[:n]:\n",
    "        synonyms = wordnet.synsets(random_word)\n",
    "        if synonyms:\n",
    "            synonym = synonyms[0].lemmas()[0].name()\n",
    "            new_words = [synonym if word == random_word else word for word in new_words]\n",
    "    return \" \".join(new_words)\n",
    "\n",
    "\n",
    "def random_insertion(sentence, n=1):\n",
    "    words = sentence.split()\n",
    "    for _ in range(n):\n",
    "        random_word = random.choice(words)\n",
    "        synonyms = wordnet.synsets(random_word)\n",
    "        if synonyms:\n",
    "            synonym = synonyms[0].lemmas()[0].name()\n",
    "            insert_position = random.randint(0, len(words))\n",
    "            words.insert(insert_position, synonym)\n",
    "    return \" \".join(words)\n",
    "\n",
    "\n",
    "def random_swap(sentence, n=1):\n",
    "    words = sentence.split()\n",
    "    for _ in range(n):\n",
    "        idx1, idx2 = random.sample(range(len(words)), 2)\n",
    "        words[idx1], words[idx2] = words[idx2], words[idx1]\n",
    "    return \" \".join(words)\n",
    "\n",
    "\n",
    "def random_deletion(sentence, p=0.2):\n",
    "    words = sentence.split()\n",
    "    if len(words) == 1:  # 如果只有一个单词，直接返回\n",
    "        return sentence\n",
    "    new_words = [word for word in words if random.uniform(0, 1) > p]\n",
    "    return \" \".join(new_words) if new_words else random.choice(words)\n",
    "\n",
    "\n",
    "def spelling_error_injection(sentence, n=1):\n",
    "    def typo(word):\n",
    "        if len(word) <= 1:\n",
    "            return word\n",
    "        idx = random.randint(0, len(word) - 2)\n",
    "        return word[:idx] + word[idx + 1] + word[idx] + word[idx + 2 :]\n",
    "\n",
    "    words = sentence.split()\n",
    "    for _ in range(n):\n",
    "        idx = random.randint(0, len(words) - 1)\n",
    "        words[idx] = typo(words[idx])\n",
    "    return \" \".join(words)\n",
    "\n",
    "\n",
    "keyboard_map = {\n",
    "    \"a\": [\"q\", \"w\", \"s\", \"z\"],\n",
    "    \"b\": [\"v\", \"g\", \"h\", \"n\"],\n",
    "}\n",
    "\n",
    "\n",
    "def keyboard_error_injection(sentence, n=1):\n",
    "    def keyboard_typo(word):\n",
    "        chars = list(word)\n",
    "        idx = random.randint(0, len(chars) - 1)\n",
    "        if chars[idx] in keyboard_map:\n",
    "            chars[idx] = random.choice(keyboard_map[chars[idx]])\n",
    "        return \"\".join(chars)\n",
    "\n",
    "    words = sentence.split()\n",
    "    for _ in range(n):\n",
    "        idx = random.randint(0, len(words) - 1)\n",
    "        words[idx] = keyboard_typo(words[idx])\n",
    "    return \" \".join(words)\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# 假设已有训练语料库的unigram分布\n",
    "unigram_freq = Counter({\"the\": 5000, \"a\": 3000, \"cat\": 1000})\n",
    "\n",
    "\n",
    "def unigram_noising(sentence, n=1):\n",
    "    words = sentence.split()\n",
    "    for _ in range(n):\n",
    "        idx = random.randint(0, len(words) - 1)\n",
    "        replacement_word = random.choices(\n",
    "            list(unigram_freq.keys()), weights=list(unigram_freq.values()), k=1\n",
    "        )[0]\n",
    "        words[idx] = replacement_word\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/snt/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "\n",
    "# 定义增强函数集合|\n",
    "def augment_text(text, times=5):\n",
    "    augmented_texts = []\n",
    "\n",
    "    for _ in range(times):\n",
    "        # EDA 操作\n",
    "        augmented_texts.append(synonym_replacement(text))\n",
    "        augmented_texts.append(random_insertion(text))\n",
    "        augmented_texts.append(random_swap(text))\n",
    "        augmented_texts.append(random_deletion(text))\n",
    "\n",
    "        # 噪声注入操作\n",
    "        augmented_texts.append(spelling_error_injection(text))\n",
    "        augmented_texts.append(keyboard_error_injection(text))\n",
    "        augmented_texts.append(unigram_noising(text))\n",
    "\n",
    "    return augmented_texts\n",
    "\n",
    "\n",
    "augmented_data = []\n",
    "for index, row in new_df.iterrows():\n",
    "    original_prompt = row[\"initial_prompt\"]\n",
    "    augmented_prompts = augment_text(original_prompt, 2)\n",
    "    for augmented_prompt in augmented_prompts:\n",
    "        augmented_data.append(\n",
    "            {\n",
    "                \"initial_prompt\": original_prompt,\n",
    "                \"augmented_prompt\": augmented_prompt,\n",
    "                \"ability\": row[\"ability\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "augmented_df = pd.DataFrame(augmented_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ability\n",
       "MT     8400\n",
       "CT     7784\n",
       "IF     7014\n",
       "CR     4536\n",
       "ICL    2030\n",
       "SUM    1526\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_df.ability.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_df = augmented_df.drop_duplicates(subset=[\"augmented_prompt\"]).reset_index(\n",
    "    drop=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ability\n",
       "MT     6662\n",
       "CT     6187\n",
       "IF     5576\n",
       "CR     3617\n",
       "ICL    1605\n",
       "SUM    1233\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_df.ability.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_df.to_csv(\n",
    "    \"/home/snt/projects_lujun/temperature_eval_github/temperature_eval/data/Bert/all_data_for_bert_training_augmented.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(\n",
    "    \"/home/snt/projects_lujun/temperature_eval_github/temperature_eval/data/Bert/all_data_for_bert_training_augmented.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm_env_lujun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
